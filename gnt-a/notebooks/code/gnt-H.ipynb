{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "下面参考gnt-E，我们改为10层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing path:  ../data/train_/00037\n",
      "Train data loaded.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../dfs/checkpoint/dnn10_model_a', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn10_model_a/model.ckpt-40000\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into ../dfs/checkpoint/dnn10_model_a/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0817199, step = 40001\n",
      "INFO:tensorflow:global_step/sec: 0.929769\n",
      "INFO:tensorflow:loss = 0.00197337, step = 40101 (107.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.644439\n",
      "INFO:tensorflow:loss = 0.0112703, step = 40201 (155.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.536353\n",
      "INFO:tensorflow:loss = 0.174575, step = 40301 (186.441 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40373 into ../dfs/checkpoint/dnn10_model_a/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.472333\n",
      "INFO:tensorflow:loss = 0.677325, step = 40401 (211.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.59099\n",
      "INFO:tensorflow:loss = 0.00482802, step = 40501 (169.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.581717\n",
      "INFO:tensorflow:loss = 10.2914, step = 40601 (171.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.599531\n",
      "INFO:tensorflow:loss = 0.00314034, step = 40701 (166.798 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40710 into ../dfs/checkpoint/dnn10_model_a/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.50834\n",
      "INFO:tensorflow:loss = 1.83204, step = 40801 (196.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.456272\n",
      "INFO:tensorflow:loss = 0.00344754, step = 40901 (219.157 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40986 into ../dfs/checkpoint/dnn10_model_a/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.368988\n",
      "INFO:tensorflow:loss = 0.0200542, step = 41001 (271.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.463966\n",
      "INFO:tensorflow:loss = 11.0881, step = 41101 (215.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.40037\n",
      "INFO:tensorflow:loss = 0.023364, step = 41201 (249.771 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41228 into ../dfs/checkpoint/dnn10_model_a/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.382918\n",
      "INFO:tensorflow:loss = 0.459688, step = 41301 (261.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.431764\n",
      "INFO:tensorflow:loss = 1.21649, step = 41401 (231.606 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41475 into ../dfs/checkpoint/dnn10_model_a/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.380803\n",
      "INFO:tensorflow:loss = 0.713622, step = 41501 (262.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.445792\n",
      "INFO:tensorflow:loss = 0.123913, step = 41601 (224.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.421816\n",
      "INFO:tensorflow:loss = 10.3552, step = 41701 (237.067 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41723 into ../dfs/checkpoint/dnn10_model_a/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.386467\n",
      "INFO:tensorflow:loss = 0.0311308, step = 41801 (258.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.432581\n",
      "INFO:tensorflow:loss = 0.00700458, step = 41901 (231.169 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41959 into ../dfs/checkpoint/dnn10_model_a/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.336962\n",
      "INFO:tensorflow:loss = 0.0211815, step = 42001 (296.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.429503\n",
      "INFO:tensorflow:loss = 0.0561531, step = 42101 (232.818 sec)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from numpy import array\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "FULL_CHARSET_SIZE = 3755\n",
    "CHARSET_SIZE = 37\n",
    "\n",
    "def input(dataset):\n",
    "    return dataset.images, dataset.labels\n",
    "\n",
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set CHARSET_SIZE to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print('Now processing path: ', truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        self.images = [rgb2gray(item) for item in image_resized]\n",
    "        \n",
    "        # convert list to numpy array\n",
    "        self.images = array(self.images)\n",
    "        self.labels = array(self.labels)\n",
    "    \n",
    "train_data = DataSetLoader(data_dir='../data/train_/')\n",
    "print ('Train data loaded.')\n",
    "\n",
    "# Specify feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[IMAGE_SIZE, IMAGE_SIZE])]\n",
    "\n",
    "# Build 8 layer DNN classifier\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns, # The input features to our model\n",
    "    hidden_units=[4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096], # 8 hidden layers\n",
    "    n_classes=CHARSET_SIZE, # survived or not {1, 0}\n",
    "    model_dir=\"../dfs/checkpoint/dnn10_model_a\", # Path to where checkpoints etc are stored\n",
    "    optimizer=tf.train.RMSPropOptimizer(\n",
    "        learning_rate=0.00001),\n",
    "    dropout=0.1)\n",
    "\n",
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(train_data)[0]},\n",
    "    y=input(train_data)[1],\n",
    "    num_epochs=None,\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "classifier.train(input_fn=train_input_fn, steps=10000)\n",
    "print ('Train done, begin to test ...')\n",
    "test_data = DataSetLoader(data_dir='../data/test_/')\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    y=input(test_data)[1],\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f023b8366d8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '../dfs/checkpoint/dnn10_model_a'}\n",
      "Now processing path:  ../data/test_/00037\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-23-00:57:10\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn10_model_a/model.ckpt-40000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-23-00:57:18\n",
      "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.836199, average_loss = 1.25737, global_step = 40000, loss = 154.377\n",
      "\n",
      "Test Accuracy: 83.619910%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/jeffcarp/example-save-and-load-a-tensorflow-model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from numpy import array\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.estimators import run_config\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "# CHARSET_SIZE = 3755\n",
    "CHARSET_SIZE = 37\n",
    "\n",
    "def input(dataset):\n",
    "    return dataset.images, dataset.labels\n",
    "\n",
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set CHARSET_SIZE to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print('Now processing path: ', truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        self.images = [rgb2gray(item) for item in image_resized]\n",
    "        \n",
    "        # convert list to numpy array\n",
    "        self.images = array(self.images)\n",
    "        self.labels = array(self.labels)\n",
    "\n",
    "# Specify feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[IMAGE_SIZE, IMAGE_SIZE])]\n",
    "\n",
    "def make_estimator(model_dir):\n",
    "    config = run_config.RunConfig(model_dir=model_dir)\n",
    "\n",
    "    return tf.estimator.DNNClassifier (\n",
    "        config=config,\n",
    "        feature_columns=feature_columns, # The input features to our model\n",
    "    hidden_units=[4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096], # 8 hidden layers\n",
    "    n_classes=CHARSET_SIZE, # survived or not {1, 0}\n",
    "    optimizer=tf.train.RMSPropOptimizer(\n",
    "        learning_rate=0.00001),\n",
    "    dropout=0.1)\n",
    "    \n",
    "\n",
    "MODEL_DIR = \"../dfs/checkpoint/dnn10_model_a\"\n",
    "model_from_checkpoint = make_estimator(MODEL_DIR)\n",
    "\n",
    "test_data = DataSetLoader(data_dir='../data/test_/')\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    y=input(test_data)[1],\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_score = model_from_checkpoint.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个在2万步时，精度为80%多；在3万步时，下降了：\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-22-06:12:18\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn10_model_a/model.ckpt-30000\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-22-06:12:36\n",
    "INFO:tensorflow:Saving dict for global step 30000: accuracy = 0.794118, average_loss = 1.42546, global_step = 30000, loss = 175.014\n",
    "\n",
    "Test Accuracy: 79.411763%\n",
    "\n",
    "\n",
    "再来一万步看看（14：13开始）：\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-23-00:57:10\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn10_model_a/model.ckpt-40000\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-23-00:57:18\n",
    "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.836199, average_loss = 1.25737, global_step = 40000, loss = 154.377\n",
    "\n",
    "Test Accuracy: 83.619910%\n",
    "\n",
    "这个还真有进步！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
