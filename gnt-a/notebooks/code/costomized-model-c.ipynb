{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是在http://58.241.217.181:15111/notebooks/work/ml/gnt-a/notebooks/code/customized-model-A.ipynb#\n",
    "的基础上，参照：\n",
    "https://www.tensorflow.org/versions/master/tutorials/layers\n",
    "来制作CNN，用于识别GNT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing path:  ../data/train_/00037\n",
      "self.images:  float64\n",
      "self.images:  float32\n",
      "Train data loaded ...\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../dfs/checkpoint/customized_model-c', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "Begin to train ...\n",
      "shape of input_layer:  Tensor(\"Reshape:0\", shape=(100, 64, 64, 1), dtype=float32)\n",
      "shape of conv1:  Tensor(\"conv2d/Relu:0\", shape=(100, 64, 64, 32), dtype=float32)\n",
      "shape of conv2:  Tensor(\"conv2d_2/Relu:0\", shape=(100, 32, 32, 64), dtype=float32) ; and shape of pool2 is:  Tensor(\"max_pooling2d_2/MaxPool:0\", shape=(100, 16, 16, 64), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-255101\n",
      "INFO:tensorflow:Saving checkpoints for 255102 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.000882058, step = 255102\n",
      "INFO:tensorflow:global_step/sec: 1.17223\n",
      "INFO:tensorflow:loss = 0.000874585, step = 255202 (85.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17929\n",
      "INFO:tensorflow:loss = 0.00194292, step = 255302 (84.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17786\n",
      "INFO:tensorflow:loss = 0.000707743, step = 255402 (84.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17446\n",
      "INFO:tensorflow:loss = 0.000948804, step = 255502 (85.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17975\n",
      "INFO:tensorflow:loss = 0.000355873, step = 255602 (84.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17954\n",
      "INFO:tensorflow:loss = 0.00221319, step = 255802 (84.778 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 255808 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.16397\n",
      "INFO:tensorflow:loss = 0.0021419, step = 255902 (85.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17842\n",
      "INFO:tensorflow:loss = 0.000717369, step = 256002 (84.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17824\n",
      "INFO:tensorflow:loss = 0.00142683, step = 256102 (84.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17\n",
      "INFO:tensorflow:loss = 0.00117108, step = 256202 (85.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17644\n",
      "INFO:tensorflow:loss = 0.000912431, step = 256302 (85.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.16996\n",
      "INFO:tensorflow:loss = 0.0009218, step = 256402 (85.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17972\n",
      "INFO:tensorflow:loss = 0.000860493, step = 256502 (84.769 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 256513 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.15586\n",
      "INFO:tensorflow:loss = 0.00104086, step = 256602 (86.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1687\n",
      "INFO:tensorflow:loss = 0.000779065, step = 256702 (85.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1647\n",
      "INFO:tensorflow:loss = 0.000774648, step = 256802 (85.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17284\n",
      "INFO:tensorflow:loss = 0.00511197, step = 256902 (85.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1683\n",
      "INFO:tensorflow:loss = 0.000622357, step = 257002 (85.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.16873\n",
      "INFO:tensorflow:loss = 0.000320295, step = 257102 (85.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.17543\n",
      "INFO:tensorflow:loss = 0.00126678, step = 257202 (85.076 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 257214 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14525\n",
      "INFO:tensorflow:loss = 0.00102524, step = 257302 (87.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12712\n",
      "INFO:tensorflow:loss = 0.00299262, step = 257402 (88.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13222\n",
      "INFO:tensorflow:loss = 0.000708936, step = 257502 (88.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13166\n",
      "INFO:tensorflow:loss = 0.000742003, step = 257602 (88.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13461\n",
      "INFO:tensorflow:loss = 0.00131471, step = 257702 (88.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12949\n",
      "INFO:tensorflow:loss = 0.00152952, step = 257802 (88.535 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 257894 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.12439\n",
      "INFO:tensorflow:loss = 0.000265525, step = 257902 (88.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12582\n",
      "INFO:tensorflow:loss = 0.00164771, step = 258002 (88.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13299\n",
      "INFO:tensorflow:loss = 0.001418, step = 258102 (88.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12841\n",
      "INFO:tensorflow:loss = 0.00136442, step = 258202 (88.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12556\n",
      "INFO:tensorflow:loss = 0.000721563, step = 258302 (88.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13402\n",
      "INFO:tensorflow:loss = 0.00134318, step = 258402 (88.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12721\n",
      "INFO:tensorflow:loss = 0.00125472, step = 258502 (88.716 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 258571 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11967\n",
      "INFO:tensorflow:loss = 0.00289658, step = 258602 (89.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1337\n",
      "INFO:tensorflow:loss = 0.000732123, step = 258702 (88.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12151\n",
      "INFO:tensorflow:loss = 0.00152025, step = 258802 (89.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15153\n",
      "INFO:tensorflow:loss = 0.00348767, step = 258902 (86.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1657\n",
      "INFO:tensorflow:loss = 0.00113551, step = 259002 (85.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1569\n",
      "INFO:tensorflow:loss = 0.000756775, step = 259102 (86.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1268\n",
      "INFO:tensorflow:loss = 0.000879171, step = 259202 (88.746 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 259255 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11663\n",
      "INFO:tensorflow:loss = 0.00229649, step = 259302 (89.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1306\n",
      "INFO:tensorflow:loss = 0.000705369, step = 259402 (88.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13102\n",
      "INFO:tensorflow:loss = 0.00123849, step = 259502 (88.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12879\n",
      "INFO:tensorflow:loss = 0.000715671, step = 259602 (88.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13109\n",
      "INFO:tensorflow:loss = 0.000267048, step = 259702 (88.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13288\n",
      "INFO:tensorflow:loss = 0.000409211, step = 259802 (88.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13295\n",
      "INFO:tensorflow:loss = 0.000570241, step = 259902 (88.265 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 259933 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.12058\n",
      "INFO:tensorflow:loss = 0.00252427, step = 260002 (89.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13014\n",
      "INFO:tensorflow:loss = 0.000560358, step = 260202 (88.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12783\n",
      "INFO:tensorflow:loss = 0.00523028, step = 260302 (88.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13071\n",
      "INFO:tensorflow:loss = 0.000318163, step = 260402 (88.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13015\n",
      "INFO:tensorflow:loss = 0.00264152, step = 260502 (88.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1264\n",
      "INFO:tensorflow:loss = 0.00729818, step = 260602 (88.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 260611 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11885\n",
      "INFO:tensorflow:loss = 0.00216656, step = 260702 (89.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12866\n",
      "INFO:tensorflow:loss = 0.00127224, step = 260802 (88.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1291\n",
      "INFO:tensorflow:loss = 0.000477532, step = 260902 (88.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13119\n",
      "INFO:tensorflow:loss = 0.000641418, step = 261002 (88.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12682\n",
      "INFO:tensorflow:loss = 0.00114612, step = 261102 (88.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12841\n",
      "INFO:tensorflow:loss = 0.00192955, step = 261202 (88.621 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 261288 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.12215\n",
      "INFO:tensorflow:loss = 0.00296776, step = 261302 (89.114 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.13281\n",
      "INFO:tensorflow:loss = 0.000396507, step = 261402 (88.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1354\n",
      "INFO:tensorflow:loss = 0.000993133, step = 261502 (88.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12678\n",
      "INFO:tensorflow:loss = 0.000898494, step = 261602 (88.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.135\n",
      "INFO:tensorflow:loss = 0.00031136, step = 261702 (88.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13003\n",
      "INFO:tensorflow:loss = 0.00156596, step = 261802 (88.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13006\n",
      "INFO:tensorflow:loss = 0.000273461, step = 261902 (88.492 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 261967 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11922\n",
      "INFO:tensorflow:loss = 0.00345932, step = 262002 (89.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12938\n",
      "INFO:tensorflow:loss = 0.000644465, step = 262102 (88.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1339\n",
      "INFO:tensorflow:loss = 0.000722043, step = 262202 (88.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1313\n",
      "INFO:tensorflow:loss = 0.00115664, step = 262302 (88.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12592\n",
      "INFO:tensorflow:loss = 0.000322912, step = 262402 (88.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12798\n",
      "INFO:tensorflow:loss = 0.000509525, step = 262502 (88.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13645\n",
      "INFO:tensorflow:loss = 0.00058777, step = 262602 (87.994 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 262645 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.12716\n",
      "INFO:tensorflow:loss = 0.00221255, step = 262702 (88.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13376\n",
      "INFO:tensorflow:loss = 0.00108243, step = 262802 (88.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13391\n",
      "INFO:tensorflow:loss = 0.00103415, step = 262902 (88.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13636\n",
      "INFO:tensorflow:loss = 0.00058966, step = 263002 (88.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13131\n",
      "INFO:tensorflow:loss = 0.00314836, step = 263102 (88.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13148\n",
      "INFO:tensorflow:loss = 0.000553863, step = 263202 (88.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12694\n",
      "INFO:tensorflow:loss = 0.00060305, step = 263302 (88.736 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 263324 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.1151\n",
      "INFO:tensorflow:loss = 0.00241369, step = 263402 (89.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13105\n",
      "INFO:tensorflow:loss = 0.00285011, step = 263502 (88.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12928\n",
      "INFO:tensorflow:loss = 0.00219496, step = 263602 (88.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12852\n",
      "INFO:tensorflow:loss = 0.00660036, step = 263702 (88.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12697\n",
      "INFO:tensorflow:loss = 0.00513144, step = 263802 (88.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13384\n",
      "INFO:tensorflow:loss = 0.000573132, step = 263902 (88.196 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 264001 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.12178\n",
      "INFO:tensorflow:loss = 0.000485531, step = 264002 (89.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13495\n",
      "INFO:tensorflow:loss = 0.00171258, step = 264102 (88.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12439\n",
      "INFO:tensorflow:loss = 0.000877574, step = 264202 (88.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12675\n",
      "INFO:tensorflow:loss = 0.000215331, step = 264302 (88.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13261\n",
      "INFO:tensorflow:loss = 0.00155346, step = 264402 (88.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13537\n",
      "INFO:tensorflow:loss = 0.00275175, step = 264502 (88.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13384\n",
      "INFO:tensorflow:loss = 0.000879888, step = 264602 (88.196 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 264679 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11771\n",
      "INFO:tensorflow:loss = 0.00109616, step = 264702 (89.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12416\n",
      "INFO:tensorflow:loss = 0.000810146, step = 264802 (88.956 sec)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from numpy import array\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.exposure import adjust_gamma\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "# CHARSET_SIZE = 3755\n",
    "CHARSET_SIZE = 37\n",
    "\n",
    "def getRndGamma():\n",
    "    rnd1 = np.random.random_sample()\n",
    "    rnd2 = np.random.random_sample()+0.001\n",
    "    rnd3 = np.random.random_sample()*100\n",
    "\n",
    "    if (rnd1 < 1/3.0):\n",
    "        return rnd3\n",
    "    elif (rnd1 < 2/3.0):\n",
    "        return 1\n",
    "    else:\n",
    "        return rnd2\n",
    "\n",
    "\n",
    "def input(dataset):\n",
    "    return dataset.images, dataset.labels\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 64, 64, 1])\n",
    "  print ('shape of input_layer: ', input_layer)\n",
    "  # with batch_size =100, shape should be: [100, 28, 28, 1]\n",
    "  # shape of input_layer:  Tensor(\"Reshape:0\", shape=(100, 64, 64, 1), dtype=float32)\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  print ('shape of conv1: ', conv1)\n",
    "  # shape of conv1:  Tensor(\"conv2d/Relu:0\", shape=(100, 64, 64, 32), dtype=float32)\n",
    "    \n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "  print ('shape of conv2: ', conv2, '; and shape of pool2 is: ', pool2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 16 * 16 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=CHARSET_SIZE)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set FLAGS.charset_size to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print('Now processing path: ', truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        image_gamma_adjust = [adjust_gamma(image, 1) for image in image_resized]\n",
    "\n",
    "        self.images = [rgb2gray(item) for item in image_gamma_adjust]\n",
    "        print ('self.images: ', self.images[0].dtype)\n",
    "        self.images = np.float32(self.images)\n",
    "        print ('self.images: ', self.images[0].dtype)\n",
    "\n",
    "        # convert list to numpy array\n",
    "        self.images = array(self.images)\n",
    "        self.labels = array(self.labels)\n",
    "\n",
    "    \n",
    "train_data = DataSetLoader(data_dir='../data/train_/')\n",
    "print ('Train data loaded ...')\n",
    "\n",
    "\n",
    "# Specify feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[IMAGE_SIZE, IMAGE_SIZE])]\n",
    "\n",
    "\n",
    "\n",
    "# Build CNN with customized function ...\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "   model_dir='../dfs/checkpoint/customized_model-c')\n",
    "\n",
    "    \n",
    "\n",
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(train_data)[0]},\n",
    "    y=input(train_data)[1],\n",
    "    num_epochs=None,\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")\n",
    "print ('Begin to train ...')\n",
    "\n",
    "classifier.train(input_fn=train_input_fn, steps=40000)\n",
    "print ('Train done ...')\n",
    "\n",
    "test_data = DataSetLoader(data_dir='../data/test_/')\n",
    "print ('Test data loaded ...')\n",
    "\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    y=input(test_data)[1],\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 关于kernel size:\n",
    "TIP: If filter height and width have the same value, you can instead specify a single integer for kernel_size—e.g., kernel_size=5.\n",
    "\n",
    "tensorflow 官网上MNIST示例，是5*5： https://www.tensorflow.org/versions/master/tutorials/layers\n",
    "\n",
    "Very small filter sizes will capture very fine details of the image. On the other hand having a bigger filter size will leave out minute details in the image.\n",
    "如果图片细节重要，则需要kernel size小\n",
    "https://www.quora.com/How-can-I-decide-the-kernel-size-output-maps-and-layers-of-CNN\n",
    "\n",
    "这个好像也没有固定答案。一般建议 3*3 , 5*5 或7*7。 一般而言，3*3可能会好些。\n",
    "https://stats.stackexchange.com/questions/296679/what-does-kernel-size-mean\n",
    "\n",
    "\n",
    "\n",
    "-> 什么叫 activation function\n",
    "\n",
    "https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f\n",
    "\n",
    "http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[1].png\n",
    "\n",
    "\n",
    "\n",
    "http://www.holehouse.org/mlclass/\n",
    "By activation, we mean the value which is computed and output by that node\n",
    "\n",
    "\n",
    "    Neural networks were developed as a way to simulate networks of neurones\n",
    "    \n",
    "    This is an artificial neurone with a sigmoid (logistic) activation function\n",
    "    关于激活函数(activation function)，其实说来话长。首先，需要知道神经网络的由来\n",
    "    \n",
    "    \n",
    "神经网络，就是对人脑神经元工作的模拟:\n",
    "\n",
    "![神经元](http://www.holehouse.org/mlclass/08_Neural_Networks_Representation_files/Image%20[2].png)\n",
    "![神经网络](http://www.holehouse.org/mlclass/08_Neural_Networks_Representation_files/Image%20[4].png)\n",
    "\n",
    "可以把上面第2个图的圈圈，想像成一个个神经元。\n",
    "\n",
    "当然，圈圈都是一个个数；那，这些数怎么算呢？第一层，叫输入层；当然，不论哪层的哪个神经元，都应该有用。那怎么叫有用呢？就是激活它，就是通过它，得到下一层神经元（圈圈）的值；如何激活它？就是使用一个函数，把这个被激活的神经元，或圈圈的数，代到这个函数中；当然，这个函数，就被称为激活函数 （activation function）了。\n",
    "\n",
    "常见的激活函数，就是大名鼎鼎的sigmoid函数\n",
    "![sigmoid函数](http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[1].png)\n",
    "\n",
    "\n",
    "sigmoid 出场\n",
    "![sigmoid函数图像](http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[2].png)\n",
    "这个函数的目的，就是将无论什么输入，都弄到0和1之间。即这个函数的y值，就是在0，1之间。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "自定义CNN雏形完成：\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-26-06:35:15\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-1000\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-26-06:35:21\n",
    "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.106335, global_step = 1000, loss = 3.58817\n",
    "\n",
    "Test Accuracy: 10.633484%\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-26-11:38:19\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-11101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-26-11:38:24\n",
    "INFO:tensorflow:Saving dict for global step 11101: accuracy = 0.78552, global_step = 11101, loss = 0.791613\n",
    "\n",
    "Test Accuracy: 78.552037%\n",
    "\n",
    "10000步时，精度不错。\n",
    "\n",
    "13000时：\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-26-12:14:59\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-13101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-26-12:15:04\n",
    "INFO:tensorflow:Saving dict for global step 13101: accuracy = 0.80543, global_step = 13101, loss = 0.680529\n",
    "\n",
    "Test Accuracy: 80.542988%\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-26-13:40:56\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-15101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-26-13:41:02\n",
    "INFO:tensorflow:Saving dict for global step 15101: accuracy = 0.826697, global_step = 15101, loss = 0.62195\n",
    "\n",
    "Test Accuracy: 82.669681%\n",
    " \n",
    " INFO:tensorflow:Starting evaluation at 2018-04-27-10:11:28\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-95101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-27-10:11:35\n",
    "INFO:tensorflow:Saving dict for global step 95101: accuracy = 0.893665, global_step = 95101, loss = 0.469633\n",
    "\n",
    "Test Accuracy: 89.366513%\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-29-02:00:37\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-115101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-29-02:00:43\n",
    "INFO:tensorflow:Saving dict for global step 115101: accuracy = 0.893665, global_step = 115101, loss = 0.471583\n",
    "\n",
    "Test Accuracy: 89.366513%\n",
    "\n",
    "下面仅做测试：\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-29-04:28:24\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-125101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-29-04:28:30\n",
    "INFO:tensorflow:Saving dict for global step 125101: accuracy = 0.895475, global_step = 125101, loss = 0.492467\n",
    "\n",
    "Test Accuracy: 89.547509%\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-29-13:00:24\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-145101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-29-13:00:30\n",
    "INFO:tensorflow:Saving dict for global step 145101: accuracy = 0.893665, global_step = 145101, loss = 0.504544\n",
    "\n",
    "Test Accuracy: 89.366513%\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-05-01-01:01:11\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-245101\n",
    "INFO:tensorflow:Finished evaluation at 2018-05-01-01:01:17\n",
    "INFO:tensorflow:Saving dict for global step 245101: accuracy = 0.897738, global_step = 245101, loss = 0.524077\n",
    "\n",
    "Test Accuracy: 89.773756%\n",
    "\n",
    "这个用了10万步，只前进了0.4%，看来，应该是难有进步了。想达到97%，是不大可能了。\n",
    "解决的方法，可能是应用gamma随机校正，来增加训练数据的复杂性。可能会提高准确度。\n",
    "\n",
    "加上了gamma 校正，再训练1万步，看看效果：\n",
    "\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-05-01-08:30:57\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-255101\n",
    "INFO:tensorflow:Finished evaluation at 2018-05-01-08:31:03\n",
    "INFO:tensorflow:Saving dict for global step 255101: accuracy = 0.894118, global_step = 255101, loss = 0.540363\n",
    "\n",
    "Test Accuracy: 89.411765%\n",
    "还是不行啊。\n",
    "\n",
    "再来4万步看看。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../dfs/checkpoint/customized_model-c', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "Now processing path:  ../data/test_/00037\n",
      "shape of input_layer:  Tensor(\"Reshape:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "shape of conv1:  Tensor(\"conv2d/Relu:0\", shape=(?, 64, 64, 32), dtype=float32)\n",
      "shape of conv2:  Tensor(\"conv2d_2/Relu:0\", shape=(?, 32, 32, 64), dtype=float32) ; and shape of pool2 is:  Tensor(\"max_pooling2d_2/MaxPool:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-01-01:01:11\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-245101\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-01-01:01:17\n",
      "INFO:tensorflow:Saving dict for global step 245101: accuracy = 0.897738, global_step = 245101, loss = 0.524077\n",
      "\n",
      "Test Accuracy: 89.773756%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/jeffcarp/example-save-and-load-a-tensorflow-model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from numpy import array\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.estimators import run_config\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "# CHARSET_SIZE = 3755\n",
    "CHARSET_SIZE = 37\n",
    "\n",
    "def input(dataset):\n",
    "    return dataset.images, dataset.labels\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 64, 64, 1])\n",
    "  print ('shape of input_layer: ', input_layer)\n",
    "  # with batch_size =100, shape should be: [100, 28, 28, 1]\n",
    "  # shape of input_layer:  Tensor(\"Reshape:0\", shape=(100, 64, 64, 1), dtype=float32)\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  print ('shape of conv1: ', conv1)\n",
    "  # shape of conv1:  Tensor(\"conv2d/Relu:0\", shape=(100, 64, 64, 32), dtype=float32)\n",
    "    \n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "  print ('shape of conv2: ', conv2, '; and shape of pool2 is: ', pool2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 16 * 16 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=CHARSET_SIZE)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set CHARSET_SIZE to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print('Now processing path: ', truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        self.images = [rgb2gray(item) for item in image_resized]\n",
    "        self.images = np.float32(self.images)\n",
    "        # or else: TypeError: Value passed to parameter 'input' has DataType float64 not in list of allowed values: float16, float32\n",
    "\n",
    "        # convert list to numpy array\n",
    "        self.images = array(self.images)\n",
    "        self.labels = array(self.labels)\n",
    "\n",
    "# Specify feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[IMAGE_SIZE, IMAGE_SIZE])]\n",
    "\n",
    "# Build CNN with customized function ...\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "   model_dir='../dfs/checkpoint/customized_model-c')\n",
    "\n",
    "\n",
    "\n",
    "# MODEL_DIR = \"../dfs/checkpoint/customized_model-c\"\n",
    "# model_from_checkpoint = make_estimator(MODEL_DIR)\n",
    "\n",
    "test_data = DataSetLoader(data_dir='../data/test_/')\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    y=input(test_data)[1],\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
