{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是在http://58.241.217.181:15111/notebooks/work/ml/gnt-a/notebooks/code/customized-model-A.ipynb#\n",
    "的基础上，参照：\n",
    "https://www.tensorflow.org/versions/master/tutorials/layers\n",
    "来制作CNN，用于识别GNT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing path:  ../data/train_/00037\n",
      "self.images:  float64\n",
      "self.images:  float32\n",
      "Train data loaded ...\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../dfs/checkpoint/customized_model-c', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "Begin to train ...\n",
      "shape of input_layer:  Tensor(\"Reshape:0\", shape=(100, 64, 64, 1), dtype=float32)\n",
      "shape of conv1:  Tensor(\"conv2d/Relu:0\", shape=(100, 64, 64, 32), dtype=float32)\n",
      "shape of conv2:  Tensor(\"conv2d_2/Relu:0\", shape=(100, 32, 32, 64), dtype=float32) ; and shape of pool2 is:  Tensor(\"max_pooling2d_2/MaxPool:0\", shape=(100, 16, 16, 64), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-95101\n",
      "INFO:tensorflow:Saving checkpoints for 95102 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00361987, step = 95102\n",
      "INFO:tensorflow:global_step/sec: 0.863657\n",
      "INFO:tensorflow:loss = 0.0022043, step = 95202 (115.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.885582\n",
      "INFO:tensorflow:loss = 0.00476026, step = 95302 (112.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.946625\n",
      "INFO:tensorflow:loss = 0.00498713, step = 95502 (105.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.930164\n",
      "INFO:tensorflow:loss = 0.00421364, step = 95602 (107.508 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 95651 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.939127\n",
      "INFO:tensorflow:loss = 0.00176952, step = 95702 (106.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09728\n",
      "INFO:tensorflow:loss = 0.0252699, step = 95802 (91.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07808\n",
      "INFO:tensorflow:loss = 0.00409144, step = 95902 (92.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08556\n",
      "INFO:tensorflow:loss = 0.00812626, step = 96002 (92.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08096\n",
      "INFO:tensorflow:loss = 0.00254949, step = 96102 (92.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07145\n",
      "INFO:tensorflow:loss = 0.00595255, step = 96202 (93.332 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 96294 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.06748\n",
      "INFO:tensorflow:loss = 0.0020392, step = 96302 (93.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09038\n",
      "INFO:tensorflow:loss = 0.00395246, step = 96402 (91.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09144\n",
      "INFO:tensorflow:loss = 0.0159941, step = 96502 (91.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08091\n",
      "INFO:tensorflow:loss = 0.0267746, step = 96602 (92.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09872\n",
      "INFO:tensorflow:loss = 0.00649206, step = 96702 (91.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09157\n",
      "INFO:tensorflow:loss = 0.0113437, step = 96802 (91.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07644\n",
      "INFO:tensorflow:loss = 0.00599685, step = 96902 (92.899 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 96947 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.07711\n",
      "INFO:tensorflow:loss = 0.00761885, step = 97002 (92.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08398\n",
      "INFO:tensorflow:loss = 0.0142058, step = 97102 (92.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09241\n",
      "INFO:tensorflow:loss = 0.00312503, step = 97202 (91.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09868\n",
      "INFO:tensorflow:loss = 0.00165066, step = 97302 (91.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.833124\n",
      "INFO:tensorflow:loss = 0.00563418, step = 97402 (120.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.786297\n",
      "INFO:tensorflow:loss = 0.00376694, step = 97502 (127.178 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 97524 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.783003\n",
      "INFO:tensorflow:loss = 0.00315895, step = 97602 (127.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.773482\n",
      "INFO:tensorflow:loss = 0.00708468, step = 97702 (129.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.780799\n",
      "INFO:tensorflow:loss = 0.00231248, step = 97802 (128.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.754878\n",
      "INFO:tensorflow:loss = 0.00973688, step = 97902 (132.472 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 97989 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.792176\n",
      "INFO:tensorflow:loss = 0.0127851, step = 98002 (126.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.805129\n",
      "INFO:tensorflow:loss = 0.00544972, step = 98102 (124.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.800223\n",
      "INFO:tensorflow:loss = 0.00556973, step = 98202 (124.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.779549\n",
      "INFO:tensorflow:loss = 0.00502987, step = 98302 (128.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.793181\n",
      "INFO:tensorflow:loss = 0.0140436, step = 98402 (126.075 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 98467 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.812613\n",
      "INFO:tensorflow:loss = 0.00436091, step = 98502 (123.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.590024\n",
      "INFO:tensorflow:loss = 0.00453373, step = 98602 (169.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.781361\n",
      "INFO:tensorflow:loss = 0.00310629, step = 98702 (127.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.58554\n",
      "INFO:tensorflow:loss = 0.00708327, step = 98802 (170.783 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 98850 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.521211\n",
      "INFO:tensorflow:loss = 0.00516148, step = 98902 (191.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.518531\n",
      "INFO:tensorflow:loss = 0.00507916, step = 99002 (192.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.532527\n",
      "INFO:tensorflow:loss = 0.00263645, step = 99102 (187.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 99165 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.529147\n",
      "INFO:tensorflow:loss = 0.0106512, step = 99202 (188.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.528477\n",
      "INFO:tensorflow:loss = 0.00239943, step = 99302 (189.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.591862\n",
      "INFO:tensorflow:loss = 0.00558232, step = 99402 (168.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.821749\n",
      "INFO:tensorflow:loss = 0.00560901, step = 99502 (121.691 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 99543 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.814816\n",
      "INFO:tensorflow:loss = 0.0114692, step = 99602 (122.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.648033\n",
      "INFO:tensorflow:loss = 0.0173955, step = 99702 (154.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.522581\n",
      "INFO:tensorflow:loss = 0.00945243, step = 99802 (191.361 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 99897 into ../dfs/checkpoint/customized_model-c/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.515432\n",
      "INFO:tensorflow:loss = 0.00848807, step = 99902 (194.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.546502\n",
      "INFO:tensorflow:loss = 0.005435, step = 100002 (182.985 sec)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from numpy import array\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "# CHARSET_SIZE = 3755\n",
    "CHARSET_SIZE = 37\n",
    "\n",
    "def input(dataset):\n",
    "    return dataset.images, dataset.labels\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 64, 64, 1])\n",
    "  print ('shape of input_layer: ', input_layer)\n",
    "  # with batch_size =100, shape should be: [100, 28, 28, 1]\n",
    "  # shape of input_layer:  Tensor(\"Reshape:0\", shape=(100, 64, 64, 1), dtype=float32)\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  print ('shape of conv1: ', conv1)\n",
    "  # shape of conv1:  Tensor(\"conv2d/Relu:0\", shape=(100, 64, 64, 32), dtype=float32)\n",
    "    \n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "  print ('shape of conv2: ', conv2, '; and shape of pool2 is: ', pool2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 16 * 16 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=CHARSET_SIZE)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set FLAGS.charset_size to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print('Now processing path: ', truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        self.images = [rgb2gray(item) for item in image_resized]\n",
    "        print ('self.images: ', self.images[0].dtype)\n",
    "        self.images = np.float32(self.images)\n",
    "        print ('self.images: ', self.images[0].dtype)\n",
    "\n",
    "        # convert list to numpy array\n",
    "        self.images = array(self.images)\n",
    "        self.labels = array(self.labels)\n",
    "\n",
    "    \n",
    "train_data = DataSetLoader(data_dir='../data/train_/')\n",
    "print ('Train data loaded ...')\n",
    "\n",
    "\n",
    "# Specify feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[IMAGE_SIZE, IMAGE_SIZE])]\n",
    "\n",
    "\n",
    "\n",
    "# Build CNN with customized function ...\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "   model_dir='../dfs/checkpoint/customized_model-c')\n",
    "\n",
    "    \n",
    "\n",
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(train_data)[0]},\n",
    "    y=input(train_data)[1],\n",
    "    num_epochs=None,\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")\n",
    "print ('Begin to train ...')\n",
    "\n",
    "classifier.train(input_fn=train_input_fn, steps=10000)\n",
    "print ('Train done ...')\n",
    "\n",
    "test_data = DataSetLoader(data_dir='../data/test_/')\n",
    "print ('Test data loaded ...')\n",
    "\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    y=input(test_data)[1],\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 关于kernel size:\n",
    "TIP: If filter height and width have the same value, you can instead specify a single integer for kernel_size—e.g., kernel_size=5.\n",
    "\n",
    "tensorflow 官网上MNIST示例，是5*5： https://www.tensorflow.org/versions/master/tutorials/layers\n",
    "\n",
    "Very small filter sizes will capture very fine details of the image. On the other hand having a bigger filter size will leave out minute details in the image.\n",
    "如果图片细节重要，则需要kernel size小\n",
    "https://www.quora.com/How-can-I-decide-the-kernel-size-output-maps-and-layers-of-CNN\n",
    "\n",
    "这个好像也没有固定答案。一般建议 3*3 , 5*5 或7*7。 一般而言，3*3可能会好些。\n",
    "https://stats.stackexchange.com/questions/296679/what-does-kernel-size-mean\n",
    "\n",
    "\n",
    "\n",
    "-> 什么叫 activation function\n",
    "\n",
    "https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f\n",
    "\n",
    "http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[1].png\n",
    "\n",
    "\n",
    "\n",
    "http://www.holehouse.org/mlclass/\n",
    "By activation, we mean the value which is computed and output by that node\n",
    "\n",
    "\n",
    "    Neural networks were developed as a way to simulate networks of neurones\n",
    "    \n",
    "    This is an artificial neurone with a sigmoid (logistic) activation function\n",
    "    关于激活函数(activation function)，其实说来话长。首先，需要知道神经网络的由来\n",
    "    \n",
    "    \n",
    "神经网络，就是对人脑神经元工作的模拟:\n",
    "\n",
    "![神经元](http://www.holehouse.org/mlclass/08_Neural_Networks_Representation_files/Image%20[2].png)\n",
    "![神经网络](http://www.holehouse.org/mlclass/08_Neural_Networks_Representation_files/Image%20[4].png)\n",
    "\n",
    "可以把上面第2个图的圈圈，想像成一个个神经元。\n",
    "\n",
    "当然，圈圈都是一个个数；那，这些数怎么算呢？第一层，叫输入层；当然，不论哪层的哪个神经元，都应该有用。那怎么叫有用呢？就是激活它，就是通过它，得到下一层神经元（圈圈）的值；如何激活它？就是使用一个函数，把这个被激活的神经元，或圈圈的数，代到这个函数中；当然，这个函数，就被称为激活函数 （activation function）了。\n",
    "\n",
    "常见的激活函数，就是大名鼎鼎的sigmoid函数\n",
    "![sigmoid函数](http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[1].png)\n",
    "\n",
    "\n",
    "sigmoid 出场\n",
    "![sigmoid函数图像](http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[2].png)\n",
    "这个函数的目的，就是将无论什么输入，都弄到0和1之间。即这个函数的y值，就是在0，1之间。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "自定义CNN雏形完成：\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-26-06:35:15\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-1000\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-26-06:35:21\n",
    "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.106335, global_step = 1000, loss = 3.58817\n",
    "\n",
    "Test Accuracy: 10.633484%\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-26-11:38:19\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-11101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-26-11:38:24\n",
    "INFO:tensorflow:Saving dict for global step 11101: accuracy = 0.78552, global_step = 11101, loss = 0.791613\n",
    "\n",
    "Test Accuracy: 78.552037%\n",
    "\n",
    "10000步时，精度不错。\n",
    "\n",
    "13000时：\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-26-12:14:59\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-13101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-26-12:15:04\n",
    "INFO:tensorflow:Saving dict for global step 13101: accuracy = 0.80543, global_step = 13101, loss = 0.680529\n",
    "\n",
    "Test Accuracy: 80.542988%\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-26-13:40:56\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-15101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-26-13:41:02\n",
    "INFO:tensorflow:Saving dict for global step 15101: accuracy = 0.826697, global_step = 15101, loss = 0.62195\n",
    "\n",
    "Test Accuracy: 82.669681%\n",
    " \n",
    " INFO:tensorflow:Starting evaluation at 2018-04-27-10:11:28\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-95101\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-27-10:11:35\n",
    "INFO:tensorflow:Saving dict for global step 95101: accuracy = 0.893665, global_step = 95101, loss = 0.469633\n",
    "\n",
    "Test Accuracy: 89.366513%\n",
    "\n",
    "\n",
    "下面仅做测试：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../dfs/checkpoint/customized_model-c', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "Now processing path:  ../data/test_/00037\n",
      "shape of input_layer:  Tensor(\"Reshape:0\", shape=(?, 64, 64, 1), dtype=float32)\n",
      "shape of conv1:  Tensor(\"conv2d/Relu:0\", shape=(?, 64, 64, 32), dtype=float32)\n",
      "shape of conv2:  Tensor(\"conv2d_2/Relu:0\", shape=(?, 32, 32, 64), dtype=float32) ; and shape of pool2 is:  Tensor(\"max_pooling2d_2/MaxPool:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-27-10:11:28\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/customized_model-c/model.ckpt-95101\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-27-10:11:35\n",
      "INFO:tensorflow:Saving dict for global step 95101: accuracy = 0.893665, global_step = 95101, loss = 0.469633\n",
      "\n",
      "Test Accuracy: 89.366513%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/jeffcarp/example-save-and-load-a-tensorflow-model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from numpy import array\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.estimators import run_config\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "# CHARSET_SIZE = 3755\n",
    "CHARSET_SIZE = 37\n",
    "\n",
    "def input(dataset):\n",
    "    return dataset.images, dataset.labels\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 64, 64, 1])\n",
    "  print ('shape of input_layer: ', input_layer)\n",
    "  # with batch_size =100, shape should be: [100, 28, 28, 1]\n",
    "  # shape of input_layer:  Tensor(\"Reshape:0\", shape=(100, 64, 64, 1), dtype=float32)\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  print ('shape of conv1: ', conv1)\n",
    "  # shape of conv1:  Tensor(\"conv2d/Relu:0\", shape=(100, 64, 64, 32), dtype=float32)\n",
    "    \n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "  print ('shape of conv2: ', conv2, '; and shape of pool2 is: ', pool2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 16 * 16 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=CHARSET_SIZE)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set CHARSET_SIZE to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print('Now processing path: ', truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        self.images = [rgb2gray(item) for item in image_resized]\n",
    "        self.images = np.float32(self.images)\n",
    "        # or else: TypeError: Value passed to parameter 'input' has DataType float64 not in list of allowed values: float16, float32\n",
    "\n",
    "        # convert list to numpy array\n",
    "        self.images = array(self.images)\n",
    "        self.labels = array(self.labels)\n",
    "\n",
    "# Specify feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[IMAGE_SIZE, IMAGE_SIZE])]\n",
    "\n",
    "# Build CNN with customized function ...\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "   model_dir='../dfs/checkpoint/customized_model-c')\n",
    "\n",
    "\n",
    "\n",
    "# MODEL_DIR = \"../dfs/checkpoint/customized_model-c\"\n",
    "# model_from_checkpoint = make_estimator(MODEL_DIR)\n",
    "\n",
    "test_data = DataSetLoader(data_dir='../data/test_/')\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    y=input(test_data)[1],\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
