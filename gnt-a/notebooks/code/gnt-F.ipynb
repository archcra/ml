{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "下面我们开始尝试做图形的预处理。\n",
    "\n",
    "图片旋转：\n",
    "下面的代码，取自gnt-C.ipynb\n",
    "http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.rotate\n",
    "    \n",
    "    \n",
    "    这个skimage： http://scikit-image.org/docs/dev/auto_examples/index.html\n",
    "        \n",
    "        感觉做图片的切分应该很合适。\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/sandbox/03755\n",
      "shape of images is:  (120, 64, 64)\n",
      "sandbox:  120 54 [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "image_data:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14576b2dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import *\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "CHARSET_SIZE = 3755\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rotate\n",
    "\n",
    "class DataIterator:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set FLAGS.charset_size to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print(truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        image_rotated = [rotate(image, np.random.random_sample()*90-45) for image in image_resized]\n",
    "        self.images = [rgb2gray(item) for item in image_rotated]\n",
    "        self.images = array(self.images)\n",
    "        print ('shape of images is: ', self.images.shape)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "test_feeder = DataIterator(data_dir='../data/sandbox/')\n",
    "print ('sandbox: ', test_feeder.size, test_feeder.labels[0], test_feeder.images[0])\n",
    "\n",
    "\n",
    "# show image\n",
    "import matplotlib.pyplot as plt\n",
    "first_array=test_feeder.images[0]\n",
    "image_data = first_array.reshape((IMAGE_SIZE, IMAGE_SIZE))\n",
    "print ('image_data: ', image_data)\n",
    "\n",
    "\n",
    "#Not sure you even have to do that if you just want to visualize it\n",
    "#first_array=255*first_array\n",
    "#first_array=first_array.astype(\"uint8\")\n",
    "plt.imshow(image_data)\n",
    "#Actually displaying the plot if you are not in interactive mode\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始，对于加入左右随机旋转45度的汉字，进行训练：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.810517258499814"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.random_sample()*90-45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../dfs/checkpoint/dnn7_model_b', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "Now processing path:  ../data/train_/00037\n",
      "Train data loaded for the 1 times.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-24000\n",
      "INFO:tensorflow:Saving checkpoints for 24001 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:loss = 25.8532, step = 24001\n",
      "INFO:tensorflow:global_step/sec: 7.89835\n",
      "INFO:tensorflow:loss = 25.9632, step = 24101 (12.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.65817\n",
      "INFO:tensorflow:loss = 14.049, step = 24201 (13.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.15994\n",
      "INFO:tensorflow:loss = 30.3948, step = 24301 (13.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.63812\n",
      "INFO:tensorflow:loss = 19.507, step = 24401 (13.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.3439\n",
      "INFO:tensorflow:loss = 23.7546, step = 24501 (13.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.24348\n",
      "INFO:tensorflow:loss = 30.3107, step = 24601 (13.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.05132\n",
      "INFO:tensorflow:loss = 23.0281, step = 24701 (14.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.3973\n",
      "INFO:tensorflow:loss = 17.6189, step = 24801 (13.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.70224\n",
      "INFO:tensorflow:loss = 11.9848, step = 24901 (12.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5981\n",
      "INFO:tensorflow:loss = 23.7525, step = 25001 (8.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4425\n",
      "INFO:tensorflow:loss = 14.736, step = 25101 (6.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6466\n",
      "INFO:tensorflow:loss = 21.2678, step = 25201 (7.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.17918\n",
      "INFO:tensorflow:loss = 27.8315, step = 25301 (13.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.14167\n",
      "INFO:tensorflow:loss = 17.6671, step = 25401 (14.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.32773\n",
      "INFO:tensorflow:loss = 16.8593, step = 25501 (13.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.64716\n",
      "INFO:tensorflow:loss = 12.3039, step = 25601 (13.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.29613\n",
      "INFO:tensorflow:loss = 27.9862, step = 25701 (13.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.37677\n",
      "INFO:tensorflow:loss = 19.4904, step = 25801 (13.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.42936\n",
      "INFO:tensorflow:loss = 16.4112, step = 25901 (13.459 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 16.3964.\n",
      "Now processing path:  ../data/train_/00037\n",
      "Train data loaded for the 2 times.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-26000\n",
      "INFO:tensorflow:Saving checkpoints for 26001 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:loss = 24.4357, step = 26001\n",
      "INFO:tensorflow:global_step/sec: 7.22594\n",
      "INFO:tensorflow:loss = 35.7881, step = 26101 (13.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.44576\n",
      "INFO:tensorflow:loss = 27.4447, step = 26201 (13.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.63484\n",
      "INFO:tensorflow:loss = 24.4438, step = 26301 (13.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.09315\n",
      "INFO:tensorflow:loss = 15.1611, step = 26401 (12.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.98187\n",
      "INFO:tensorflow:loss = 18.3314, step = 26501 (12.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.60735\n",
      "INFO:tensorflow:loss = 26.4192, step = 26601 (13.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.54452\n",
      "INFO:tensorflow:loss = 25.1897, step = 26701 (13.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.43645\n",
      "INFO:tensorflow:loss = 18.4185, step = 26801 (13.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.84007\n",
      "INFO:tensorflow:loss = 25.5161, step = 26901 (12.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.61791\n",
      "INFO:tensorflow:loss = 32.2035, step = 27001 (13.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.45528\n",
      "INFO:tensorflow:loss = 23.9342, step = 27101 (13.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.62151\n",
      "INFO:tensorflow:loss = 28.7525, step = 27201 (13.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.38951\n",
      "INFO:tensorflow:loss = 17.9475, step = 27301 (13.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.74734\n",
      "INFO:tensorflow:loss = 23.7448, step = 27401 (12.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.71662\n",
      "INFO:tensorflow:loss = 16.1916, step = 27501 (12.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.64264\n",
      "INFO:tensorflow:loss = 23.3377, step = 27601 (13.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.48637\n",
      "INFO:tensorflow:loss = 18.8721, step = 27701 (13.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5352\n",
      "INFO:tensorflow:loss = 11.5057, step = 27801 (13.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.66155\n",
      "INFO:tensorflow:loss = 20.6608, step = 27901 (13.052 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.2381.\n",
      "Now processing path:  ../data/train_/00037\n",
      "Train data loaded for the 3 times.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-28000\n",
      "INFO:tensorflow:Saving checkpoints for 28001 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:loss = 24.1692, step = 28001\n",
      "INFO:tensorflow:global_step/sec: 7.27511\n",
      "INFO:tensorflow:loss = 19.6007, step = 28101 (13.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.47755\n",
      "INFO:tensorflow:loss = 35.4801, step = 28201 (13.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.62848\n",
      "INFO:tensorflow:loss = 22.4131, step = 28301 (13.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.764\n",
      "INFO:tensorflow:loss = 20.3104, step = 28401 (12.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5427\n",
      "INFO:tensorflow:loss = 26.1784, step = 28501 (8.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4365\n",
      "INFO:tensorflow:loss = 18.4082, step = 28601 (7.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6621\n",
      "INFO:tensorflow:loss = 19.5821, step = 28701 (7.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.67972\n",
      "INFO:tensorflow:loss = 26.4726, step = 28801 (13.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.45594\n",
      "INFO:tensorflow:loss = 20.8292, step = 28901 (13.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.58206\n",
      "INFO:tensorflow:loss = 28.7194, step = 29001 (13.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.62689\n",
      "INFO:tensorflow:loss = 28.462, step = 29101 (13.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.76881\n",
      "INFO:tensorflow:loss = 19.6046, step = 29201 (12.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.77543\n",
      "INFO:tensorflow:loss = 20.6423, step = 29301 (12.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.62123\n",
      "INFO:tensorflow:loss = 12.4091, step = 29401 (13.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.56778\n",
      "INFO:tensorflow:loss = 11.2918, step = 29501 (13.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.59443\n",
      "INFO:tensorflow:loss = 14.3993, step = 29601 (13.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.64539\n",
      "INFO:tensorflow:loss = 19.4561, step = 29701 (13.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55304\n",
      "INFO:tensorflow:loss = 21.3933, step = 29801 (13.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5115\n",
      "INFO:tensorflow:loss = 11.8388, step = 29901 (13.313 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 26.4253.\n",
      "Now processing path:  ../data/train_/00037\n",
      "Train data loaded for the 4 times.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-30000\n",
      "INFO:tensorflow:Saving checkpoints for 30001 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:loss = 29.7463, step = 30001\n",
      "INFO:tensorflow:global_step/sec: 7.39865\n",
      "INFO:tensorflow:loss = 28.8769, step = 30101 (13.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.44795\n",
      "INFO:tensorflow:loss = 18.35, step = 30201 (13.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.40394\n",
      "INFO:tensorflow:loss = 21.4795, step = 30301 (13.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.17802\n",
      "INFO:tensorflow:loss = 20.9028, step = 30401 (12.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 29.9558, step = 30501 (13.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.47321\n",
      "INFO:tensorflow:loss = 21.8609, step = 30601 (13.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.57952\n",
      "INFO:tensorflow:loss = 12.13, step = 30701 (13.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55048\n",
      "INFO:tensorflow:loss = 18.5135, step = 30801 (13.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55848\n",
      "INFO:tensorflow:loss = 13.3945, step = 30901 (13.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.61169\n",
      "INFO:tensorflow:loss = 16.4063, step = 31001 (13.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.7875\n",
      "INFO:tensorflow:loss = 19.7503, step = 31101 (12.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.87114\n",
      "INFO:tensorflow:loss = 7.47633, step = 31201 (12.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.60528\n",
      "INFO:tensorflow:loss = 5.50955, step = 31301 (13.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.51568\n",
      "INFO:tensorflow:loss = 11.6992, step = 31401 (13.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.74778\n",
      "INFO:tensorflow:loss = 12.7621, step = 31501 (12.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.64011\n",
      "INFO:tensorflow:loss = 25.6241, step = 31601 (13.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50958\n",
      "INFO:tensorflow:loss = 8.38789, step = 31701 (13.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.76074\n",
      "INFO:tensorflow:loss = 10.874, step = 31801 (12.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5997\n",
      "INFO:tensorflow:loss = 12.5113, step = 31901 (13.155 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20.4047.\n",
      "Now processing path:  ../data/train_/00037\n",
      "Train data loaded for the 5 times.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-32000\n",
      "INFO:tensorflow:Saving checkpoints for 32001 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:loss = 19.2013, step = 32001\n",
      "INFO:tensorflow:global_step/sec: 13.4961\n",
      "INFO:tensorflow:loss = 24.552, step = 32101 (7.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4178\n",
      "INFO:tensorflow:loss = 26.3283, step = 32201 (7.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.30048\n",
      "INFO:tensorflow:loss = 25.2533, step = 32301 (12.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.80098\n",
      "INFO:tensorflow:loss = 20.7753, step = 32401 (12.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.67196\n",
      "INFO:tensorflow:loss = 26.5792, step = 32501 (13.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.87911\n",
      "INFO:tensorflow:loss = 13.676, step = 32601 (12.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.65947\n",
      "INFO:tensorflow:loss = 19.1757, step = 32701 (13.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.65861\n",
      "INFO:tensorflow:loss = 22.689, step = 32801 (13.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.74228\n",
      "INFO:tensorflow:loss = 18.1077, step = 32901 (12.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.79628\n",
      "INFO:tensorflow:loss = 16.9016, step = 33001 (12.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.62283\n",
      "INFO:tensorflow:loss = 9.70753, step = 33101 (13.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.58354\n",
      "INFO:tensorflow:loss = 22.2901, step = 33201 (13.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.70645\n",
      "INFO:tensorflow:loss = 21.1536, step = 33301 (12.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.57187\n",
      "INFO:tensorflow:loss = 11.1136, step = 33401 (13.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.41227\n",
      "INFO:tensorflow:loss = 12.7226, step = 33501 (13.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.76814\n",
      "INFO:tensorflow:loss = 11.2984, step = 33601 (12.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.76083\n",
      "INFO:tensorflow:loss = 8.8354, step = 33701 (12.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.72162\n",
      "INFO:tensorflow:loss = 5.77149, step = 33801 (12.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.92558\n",
      "INFO:tensorflow:loss = 22.8949, step = 33901 (12.619 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10.163.\n",
      "Now processing path:  ../data/train_/00037\n",
      "Train data loaded for the 6 times.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-34000\n",
      "INFO:tensorflow:Saving checkpoints for 34001 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:loss = 17.219, step = 34001\n",
      "INFO:tensorflow:global_step/sec: 7.3635\n",
      "INFO:tensorflow:loss = 16.944, step = 34101 (13.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.29428\n",
      "INFO:tensorflow:loss = 13.7381, step = 34201 (13.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.87794\n",
      "INFO:tensorflow:loss = 10.0505, step = 34301 (12.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5703\n",
      "INFO:tensorflow:loss = 20.5018, step = 34401 (13.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.63275\n",
      "INFO:tensorflow:loss = 14.1043, step = 34501 (13.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.75278\n",
      "INFO:tensorflow:loss = 26.7516, step = 34601 (12.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.59513\n",
      "INFO:tensorflow:loss = 14.6822, step = 34701 (13.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.67591\n",
      "INFO:tensorflow:loss = 16.1989, step = 34801 (13.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.64367\n",
      "INFO:tensorflow:loss = 13.6396, step = 34901 (13.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.52536\n",
      "INFO:tensorflow:loss = 30.4727, step = 35001 (13.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.64305\n",
      "INFO:tensorflow:loss = 10.0629, step = 35101 (13.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.69565\n",
      "INFO:tensorflow:loss = 24.18, step = 35201 (12.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.56612\n",
      "INFO:tensorflow:loss = 12.7342, step = 35301 (13.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.86266\n",
      "INFO:tensorflow:loss = 16.3222, step = 35401 (12.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.45113\n",
      "INFO:tensorflow:loss = 11.7297, step = 35501 (13.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.68569\n",
      "INFO:tensorflow:loss = 14.3524, step = 35601 (13.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55741\n",
      "INFO:tensorflow:loss = 12.9832, step = 35701 (13.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.4956\n",
      "INFO:tensorflow:loss = 17.0502, step = 35801 (13.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50713\n",
      "INFO:tensorflow:loss = 19.9086, step = 35901 (13.321 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.24067.\n",
      "Now processing path:  ../data/train_/00037\n",
      "Train data loaded for the 7 times.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-36000\n",
      "INFO:tensorflow:Saving checkpoints for 36001 into ../dfs/checkpoint/dnn7_model_b/model.ckpt.\n",
      "INFO:tensorflow:loss = 7.69172, step = 36001\n",
      "INFO:tensorflow:global_step/sec: 7.85155\n",
      "INFO:tensorflow:loss = 16.5847, step = 36101 (12.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.44875\n",
      "INFO:tensorflow:loss = 12.5742, step = 36201 (13.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.54472\n",
      "INFO:tensorflow:loss = 18.6047, step = 36301 (13.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.65368\n",
      "INFO:tensorflow:loss = 19.2988, step = 36401 (13.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.76114\n",
      "INFO:tensorflow:loss = 9.57412, step = 36501 (12.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.79206\n",
      "INFO:tensorflow:loss = 21.7098, step = 36601 (12.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.71978\n",
      "INFO:tensorflow:loss = 8.9247, step = 36701 (12.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5494\n",
      "INFO:tensorflow:loss = 16.7562, step = 36801 (13.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.57478\n",
      "INFO:tensorflow:loss = 6.2675, step = 36901 (13.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.65815\n",
      "INFO:tensorflow:loss = 15.7393, step = 37001 (13.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50082\n",
      "INFO:tensorflow:loss = 10.6781, step = 37101 (13.332 sec)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from numpy import array\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rotate\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "FULL_CHARSET_SIZE = 3755\n",
    "CHARSET_SIZE = 37\n",
    "\n",
    "def input(dataset):\n",
    "    return dataset.images, dataset.labels\n",
    "\n",
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set CHARSET_SIZE to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print('Now processing path: ', truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        image_rotated = [rotate(image, np.random.random_sample()*90-45) for image in image_resized]\n",
    "        self.images = [rgb2gray(item) for item in image_rotated]\n",
    "        \n",
    "        # convert list to numpy array\n",
    "        self.images = array(self.images)\n",
    "        self.labels = array(self.labels)\n",
    "\n",
    "# Specify feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[IMAGE_SIZE, IMAGE_SIZE])]\n",
    "\n",
    "# Build 2 layer DNN classifier\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[1024, 1024, 1024, 1024, 1024],\n",
    "    optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "    n_classes=CHARSET_SIZE,\n",
    "    dropout=0.1,\n",
    "    model_dir=\"../dfs/checkpoint/dnn7_model_b\"\n",
    ")\n",
    "for i in range(10):\n",
    "    train_data = DataSetLoader(data_dir='../data/train_/')\n",
    "    print ('Train data loaded for the %d times.'%(i+1))\n",
    "    # Define the training inputs\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": input(train_data)[0]},\n",
    "        y=input(train_data)[1],\n",
    "        num_epochs=None,\n",
    "        batch_size=50,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    classifier.train(input_fn=train_input_fn, steps=2000)\n",
    "\n",
    "\n",
    "print ('Train done, begin to test ...')\n",
    "test_data = DataSetLoader(data_dir='../data/test_/')\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    y=input(test_data)[1],\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始测试：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f63e0750e80>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '../dfs/checkpoint/dnn7_model_b'}\n",
      "Now processing path:  ../data/test_/00037\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-10:07:22\n",
      "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-44000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-10:07:24\n",
      "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.745249, average_loss = 1.10402, global_step = 44000, loss = 135.549\n",
      "\n",
      "Test Accuracy: 74.524885%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from: https://www.kaggle.com/jeffcarp/example-save-and-load-a-tensorflow-model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from numpy import array\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.estimators import run_config\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "# CHARSET_SIZE = 3755\n",
    "CHARSET_SIZE = 37\n",
    "\n",
    "def input(dataset):\n",
    "    return dataset.images, dataset.labels\n",
    "\n",
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        # Set CHARSET_SIZE to a small value if available computation power is limited.\n",
    "        truncate_path = data_dir + ('%05d' % CHARSET_SIZE)\n",
    "        print('Now processing path: ', truncate_path)\n",
    "        image_names = []\n",
    "        for root, sub_folder, file_list in os.walk(data_dir):\n",
    "            if root < truncate_path:\n",
    "                image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "        random.shuffle(image_names)\n",
    "        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in image_names]\n",
    "        images_rgb = [imread(file_name) for file_name in image_names]\n",
    "        image_resized = [resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in images_rgb]\n",
    "        self.images = [rgb2gray(item) for item in image_resized]\n",
    "        \n",
    "        # convert list to numpy array\n",
    "        self.images = array(self.images)\n",
    "        self.labels = array(self.labels)\n",
    "\n",
    "# Specify feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[IMAGE_SIZE, IMAGE_SIZE])]\n",
    "\n",
    "def make_estimator(model_dir):\n",
    "    config = run_config.RunConfig(model_dir=model_dir)\n",
    "\n",
    "    return tf.estimator.DNNClassifier (\n",
    "        config=config,\n",
    "        feature_columns=feature_columns,\n",
    "    hidden_units=[1024, 1024, 1024, 1024, 1024],\n",
    "    optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "    n_classes=CHARSET_SIZE,\n",
    "    dropout=0.1)\n",
    "    \n",
    "\n",
    "MODEL_DIR = \"../dfs/checkpoint/dnn7_model_b\"\n",
    "model_from_checkpoint = make_estimator(MODEL_DIR)\n",
    "\n",
    "test_data = DataSetLoader(data_dir='../data/test_/')\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    y=input(test_data)[1],\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": input(test_data)[0]},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_score = model_from_checkpoint.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面第一轮，约24000步时，精度为76%\n",
    "```\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-21-08:54:21\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-24000\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-21-08:54:24\n",
    "INFO:tensorflow:Saving dict for global step 24000: accuracy = 0.762443, average_loss = 0.915754, global_step = 24000, loss = 112.434\n",
    "\n",
    "Test Accuracy: 76.244342%\n",
    "```\n",
    "\n",
    "再来一轮20000步，看看有否长进。\n",
    "\n",
    "再来2万步后，精度下降了：\n",
    "\n",
    "INFO:tensorflow:Starting evaluation at 2018-04-21-10:07:22\n",
    "INFO:tensorflow:Restoring parameters from ../dfs/checkpoint/dnn7_model_b/model.ckpt-44000\n",
    "INFO:tensorflow:Finished evaluation at 2018-04-21-10:07:24\n",
    "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.745249, average_loss = 1.10402, global_step = 44000, loss = 135.549\n",
    "\n",
    "Test Accuracy: 74.524885%\n",
    "\n",
    "\n",
    "使用随机左右旋转45度以内的数据进行训练，分别进行了2万步。精度在第二轮时，下降了。第一轮约为76%，第二轮约为74%。\n",
    "\n",
    "理论上，如果计算资源足够，将旋转和gamma校正应用于训练数据，应该会提高精度 - 前提是学习步骤要足够多- 如100万步。\n",
    "\n",
    "\n",
    "学习步骤少的话，使用旋转可能会将模型转昏。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
